import 'dotenv/config'
import { TextLoader } from 'langchain/document_loaders/fs/text'
import { ChatDeepSeek } from '@langchain/deepseek'
import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters'
import { Send } from '@langchain/langgraph'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { Document } from '@langchain/core/documents'
import { collapseDocs, splitListOfDocs } from 'langchain/chains/combine_documents/reduce'

// åŠ è½½æœ¬åœ°æ–‡æ¡£ï¼Œæ¨¡æ‹Ÿä»æ•°æ®åº“è·å–æ–‡æ¡£å†…å®¹
async function loadMarkdownWithLoader(filePath) {
  const loader = new TextLoader(filePath)
  return await loader.load()
}

const doc = await loadMarkdownWithLoader('./data/blog.md')
const textSplitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1000,
  chunkOverlap: 200
})
const splitDocs  = await textSplitter.splitDocuments(doc)

// æ£€æŸ¥APIå¯†é’¥
if (!process.env.DEEPSEEK_API_KEY) {
  console.error('âŒ é”™è¯¯: æœªæ‰¾åˆ° DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡')
  console.log('è¯·åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : DEEPSEEK_API_KEY=your_api_key_here')
  process.exit(1)
}

const llm = new ChatDeepSeek({
  model: 'deepseek-chat',
  temperature: 0,
  apiKey: process.env.DEEPSEEK_API_KEY
})

const mapSummaries = (state) => {
  // state.contents æ˜¯åˆ†å‰²å‡ºæ¥çš„æ–‡æ¡£å†…å®¹æ•°ç»„
  return state.contents.map(
    (content) => new Send('generateSummary', { content }) // æ¯ä¸ªæ–‡æ¡£å†…å®¹éƒ½è°ƒç”¨ generateSummary
  )
}

const mapPrompt = ChatPromptTemplate.fromMessages([
  ['user', 'è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œåªè¾“å‡ºæ€»ç»“å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è¯´æ˜ã€åˆ†ææˆ–å»ºè®®ï¼š\n\n{context}'],
])

// æ ¹æ®æ–‡æ¡£ï¼Œç”Ÿæˆæ€»ç»“
const generateSummary = async (state) => {
  // state.content æ˜¯åˆ†å‰²å‡ºæ¥çš„ä¸€æ®µæ–‡æ¡£å†…å®¹
  const prompt = await mapPrompt.invoke({ context: state.content })
  const response = await llm.invoke(prompt)
  
  const summary = String(response.content)
  return { summaries: [summary] }
}

const collectSummaries = async (state) => {
  return {
    collapsedSummaries: state.summaries.map(
      (summary) => new Document({ pageContent: summary })
    ),
  }
}

let tokenMax = 1500 // è®¾ç½®æœ€å¤§ token é™åˆ¶
async function lengthFunction(documents) {
  const tokenCounts = await Promise.all(
    documents.map(async (doc) => {
      return doc.pageContent.length
    })
  )
  return tokenCounts.reduce((sum, count) => sum + count, 0)
}

// ç»§ç»­åˆå¹¶ï¼Œè¿˜æ˜¯ç”Ÿæˆæœ€ç»ˆæ€»ç»“ï¼Ÿ
async function shouldCollapse(state) {
  let numTokens = await lengthFunction(state.collapsedSummaries)
  if (numTokens > tokenMax) {
    return 'collapseSummaries'
  } else {
    return 'generateFinalSummary'
  }
}

const reducePrompt = ChatPromptTemplate.fromMessages([
  [
    'user',
    `ä¸‹é¢æ˜¯ä¸€ç»„æ€»ç»“:
    {docs}
    
    è¯·å°†è¿™äº›æ€»ç»“åˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„æ€»ç»“ã€‚è¦æ±‚ï¼š
    1. åªè¾“å‡ºæœ€ç»ˆæ€»ç»“å†…å®¹
    2. ä¸è¦åŒ…å«ä»»ä½•å…ƒä¿¡æ¯ã€è¯´æ˜æˆ–åˆ†æ
    3. ä¸è¦æåŠ"æ”¹å†™"ã€"ä¼˜åŒ–"ç­‰è¿‡ç¨‹ä¿¡æ¯
    4. ç›´æ¥ç»™å‡ºæ€»ç»“ç»“æœ`,
  ],
])

async function _reduce(input) {
  const prompt = await reducePrompt.invoke({ docs: input })
  const response = await llm.invoke(prompt)
  return String(response.content)
}

// ç”Ÿæˆæœ€åçš„æ€»ç»“
const generateFinalSummary = async (state) => {
  const response = await _reduce(state.collapsedSummaries)
  return { finalSummary: response }
}

const collapseSummaries = async (state) => {
  const docLists = splitListOfDocs(
    state.collapsedSummaries,
    lengthFunction,
    tokenMax
  )
  const results = []
  
  for (let i = 0; i < docLists.length; i++) {
    const docList = docLists[i]
    const collapsed = await collapseDocs(docList, _reduce) // æŠŠ docList ä¸­çš„æ–‡æ¡£åˆå¹¶ä¸ºä¸€ä¸ªæ–‡æ¡£
    results.push(collapsed)
  }

  return { collapsedSummaries: results }
}


import { StateGraph, Annotation } from '@langchain/langgraph'

const OverallState = Annotation.Root({
  contents: Annotation,
  summaries: Annotation({
    reducer: (state, update) => state.concat(update),
  }),
  collapsedSummaries: Annotation,
  finalSummary: Annotation,
})

const graph = new StateGraph(OverallState)
  .addNode('generateSummary', generateSummary)
  .addNode('collectSummaries', collectSummaries)
  .addNode('collapseSummaries', collapseSummaries)
  .addNode('generateFinalSummary', generateFinalSummary)
  .addConditionalEdges('__start__', mapSummaries, ['generateSummary'])
  .addEdge('generateSummary', 'collectSummaries')
  .addConditionalEdges('collectSummaries', shouldCollapse, [
    'collapseSummaries',
    'generateFinalSummary',
  ])
  .addConditionalEdges('collapseSummaries', shouldCollapse, [
    'collapseSummaries',
    'generateFinalSummary',
  ])
  .addEdge('generateFinalSummary', '__end__')
  
const app = graph.compile()

let finalSummary = null
let summaryCount = 0
let totalSteps = splitDocs.length + 3 // æ–‡æ¡£ç‰‡æ®µæ•° + æ”¶é›† + åˆå¹¶ + æœ€ç»ˆæ€»ç»“
let startMessageShown = false

// åˆ›å»ºåŠ¨æ€åŠ è½½æ¡
function showLoadingBar(current, total, message) {
  const percentage = Math.round((current / total) * 100)
  const barLength = 30
  const filledLength = Math.round((current / total) * barLength)
  const bar = 'â–ˆ'.repeat(filledLength) + 'â–‘'.repeat(barLength - filledLength)
  
  // åˆ›å»ºæ—‹è½¬åŠ¨ç”»
  const spinners = ['â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡', 'â ']
  const spinner = spinners[current % spinners.length]
  
  process.stdout.write(`\r${spinner} ${message} [${bar}] ${percentage}%`)
}


let currentStep = 0
let waitingInterval = null

// æ˜¾ç¤ºå¼€å§‹æ¶ˆæ¯
console.log('ğŸš€ å¼€å§‹æ–‡æ¡£æ€»ç»“æµç¨‹...\n')

for await (const step of await app.stream(
  { contents: splitDocs.map((doc) => doc.pageContent) },
  { recursionLimit: 10 }
)) {
  // æ¸…é™¤ä¹‹å‰çš„ç­‰å¾…åŠ¨ç”»
  if (waitingInterval) {
    clearInterval(waitingInterval)
    waitingInterval = null
  }
  
  // å¦‚æœæ˜¯ç”Ÿæˆæ€»ç»“æ­¥éª¤
  if (step.hasOwnProperty('generateSummary')) {
    summaryCount++
    currentStep++
    showLoadingBar(currentStep, totalSteps, 'âš¡ æ­£åœ¨åˆ†ææ–‡æ¡£ç‰‡æ®µ')
  }
  
  // å¦‚æœæ˜¯æ”¶é›†æ€»ç»“æ­¥éª¤
  if (step.hasOwnProperty('collectSummaries')) {
    currentStep++
    // å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿›å…¥æ”¶é›†é˜¶æ®µï¼Œæ¸…é™¤å¼€å§‹æ¶ˆæ¯
    if (!startMessageShown) {
      // æ¸…é™¤æ§åˆ¶å°ï¼Œç§»é™¤å¼€å§‹æ¶ˆæ¯
      console.clear()
      startMessageShown = true
    }
    showLoadingBar(currentStep, totalSteps, 'ğŸ“‹ æ­£åœ¨æ”¶é›†æ€»ç»“å†…å®¹')
  }
  
  // å¦‚æœæ˜¯åˆå¹¶æ€»ç»“æ­¥éª¤
  if (step.hasOwnProperty('collapseSummaries')) {
    currentStep++
    showLoadingBar(currentStep, totalSteps, 'ğŸ”„ æ­£åœ¨åˆå¹¶æ€»ç»“å†…å®¹')
  }
  
  // å¦‚æœæ˜¯æœ€ç»ˆæ€»ç»“æ­¥éª¤
  if (step.hasOwnProperty('generateFinalSummary')) {
    currentStep++
    showLoadingBar(currentStep, totalSteps, 'âœ¨ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæ€»ç»“')
    finalSummary = step.generateFinalSummary
  }
  
  // æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
  await new Promise(resolve => setTimeout(resolve, 200))
}

// æ¸…é™¤åŠ è½½æ¡
process.stdout.write('\r' + ' '.repeat(100) + '\r')

// æµå¼æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“ï¼ˆæ‰“å­—æ•ˆæœï¼‰
if (finalSummary) {
  // å¤„ç†ä¸åŒç±»å‹çš„ finalSummary
  let summaryText = ''
  if (typeof finalSummary === 'string') {
    summaryText = finalSummary
  } else if (typeof finalSummary === 'object' && finalSummary !== null) {
    // å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•æå–å†…å®¹
    if (finalSummary.finalSummary) {
      summaryText = String(finalSummary.finalSummary)
    } else if (finalSummary.content) {
      summaryText = String(finalSummary.content)
    } else {
      summaryText = JSON.stringify(finalSummary, null, 2)
    }
  } else {
    summaryText = String(finalSummary)
  }
  
  // æ‰“å­—æ•ˆæœæ˜¾ç¤º
  // console.log('ğŸ“„ æœ€ç»ˆæ€»ç»“:')
  
  const words = summaryText.split('')
  for (let i = 0; i < words.length; i++) {
    process.stdout.write(words[i])
    await new Promise(resolve => setTimeout(resolve, 30)) // é€å­—ç¬¦æ˜¾ç¤ºæ•ˆæœ
  }
  console.log('\n')
  console.log('â”€'.repeat(50))
} else {
  console.log('âŒ æœªèƒ½ç”Ÿæˆæœ€ç»ˆæ€»ç»“')
}
